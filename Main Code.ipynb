{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zmCLjp4pgjT",
    "outputId": "ae617c39-680c-484c-f9b8-c354d322e750"
   },
   "outputs": [],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'bone-fracture-detection-computer-vision-project:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4296838%2F7391382%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240811%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240811T181410Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D55135b7e6ad141faefafe510657bceceb42eca6737fc52043406135ad5bf956ff34ace16f87ec6a2678dc2be09858dc6dfd53639a21d824362f62e026e968400ffd9522a0e3f08c3c780a2cd0ea5c7328b0736d902c611aef58b0d9c83b6e5c622e50cea4b58e8929361c00ab4b7b3d4aa6bf6f884db110010d7a585f24cb34cdc1183e9d49a7c49cf82065d12b360278ab2b5d859e69f5ed54703217d528d7b5d0ce78fe9d0454ec807eefbf997441c1e748ef4fc0faf4e4b307bbe1850b01109d24083e8f69a348a4d0b68db2a2ad1d70afed69249a6df1ce6791e22628474f8695f1860b47b38cbd09f287a6204bfd11806880c9d5f1605810ea727d582d6'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAKmfXFApgjV"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import albumentations as A\n",
    "# import torchsummary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "BS=16\n",
    "LR=0.00005\n",
    "epochs=20\n",
    "IS=256\n",
    "D='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_classes = 7\n",
    "classes=['elbow positive', 'fingers positive', 'forearm fracture', 'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive']\n",
    "c2l={k:v for k,v in list(zip(classes,list(range(num_classes))))}\n",
    "l2c={v:k for k,v in c2l.items()}\n",
    "\n",
    "dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project'\n",
    "train_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/train'\n",
    "train_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/train/images'))\n",
    "train_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/train/labels'))\n",
    "\n",
    "val_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/valid'\n",
    "val_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/valid/images'))\n",
    "val_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/valid/labels'))\n",
    "\n",
    "test_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/test'\n",
    "test_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/test/images'))\n",
    "test_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/test/labels'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU1-iPSvpgjW"
   },
   "outputs": [],
   "source": [
    "def unconvert(width, height, x, y, w, h):\n",
    "\n",
    "    xmax = int((x*width) + (w * width)/2.0)\n",
    "    xmin = int((x*width) - (w * width)/2.0)\n",
    "    ymax = int((y*height) + (h * height)/2.0)\n",
    "    ymin = int((y*height) - (h * height)/2.0)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhE1X7g2pgjW"
   },
   "outputs": [],
   "source": [
    "augs=A.Compose([\n",
    "    A.Resize(IS,IS),\n",
    "],bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']), is_check_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QECTpWOwpgjX"
   },
   "outputs": [],
   "source": [
    "class FractureData(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, img_paths, target_paths, augs=None):\n",
    "        self.dir_path=dir_path\n",
    "        self.img_paths=img_paths\n",
    "        self.target_paths=target_paths\n",
    "        self.augs=augs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        ip=os.path.join(self.dir_path,'images',self.img_paths[idx])\n",
    "        tp=os.path.join(self.dir_path,'labels',self.target_paths[idx])\n",
    "\n",
    "        image=cv2.imread(ip)\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        H,W,_=image.shape\n",
    "\n",
    "        file=open(tp,'r')\n",
    "        target=list(map(float,file.read().split()))\n",
    "\n",
    "        try:\n",
    "            label=[target.pop(0)]\n",
    "            bbox=[]\n",
    "            i=0\n",
    "            while i<len(target):\n",
    "                x,y,w,h=target[i:i+4]\n",
    "                bbox.append([*unconvert(W,H,x,y,w,h)])\n",
    "                i+=4\n",
    "            label=label*len(bbox)\n",
    "\n",
    "            if self.augs!=None:\n",
    "                data=self.augs(image=image,bboxes=bbox,class_labels=['None']*len(label))\n",
    "                image=data['image']\n",
    "                bbox=data['bboxes']\n",
    "        except:\n",
    "            if idx+1<len(self.img_paths):\n",
    "                return self.__getitem__(idx+1)\n",
    "            else:\n",
    "                return self.__getitem__(0)\n",
    "\n",
    "        image=torch.Tensor(np.transpose(image,(2,0,1)))/255.0\n",
    "        bbox=torch.Tensor(bbox).long()\n",
    "        label=torch.Tensor(label).long()\n",
    "\n",
    "        annot={'boxes':bbox,'labels':label}\n",
    "\n",
    "        return image, annot\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUQNdKEbpgjX",
    "outputId": "5f483dd7-38d5-495d-d984-bd71ae776462"
   },
   "outputs": [],
   "source": [
    "trainset=FractureData(train_dir_path, train_img_paths, train_target_paths, augs)\n",
    "valset=FractureData(val_dir_path, val_img_paths, val_target_paths, augs)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=BS,collate_fn=trainset.collate_fn)\n",
    "valloader=torch.utils.data.DataLoader(valset,batch_size=BS,collate_fn=valset.collate_fn)\n",
    "\n",
    "\n",
    "testset=FractureData(test_dir_path, test_img_paths, test_target_paths, augs)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=BS,collate_fn=valset.collate_fn)\n",
    "print(f'Training Data:- {len(testset)} images divided into {len(testloader)} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NER7VT2WpgjX"
   },
   "outputs": [],
   "source": [
    "for image,target in testloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGAqYOB4pgjY"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrFknhOepgjZ",
    "outputId": "4110c830-9fc2-496a-e7cc-be93e16e6d24",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model=torchvision.models.detection.fasterrcnn_resnet50_fpn(preTrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.to(D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "Qy3vDOUEp3Yw",
    "outputId": "5d797fbd-88d9-40c3-deae-260f6a746788"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"C:\\\\Users\\\\FPCC\\\\Desktop\\\\Bone Fracture Detection Using RCNN\\\\model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CafCRpscpgja"
   },
   "outputs": [],
   "source": [
    "\n",
    "def f(img):\n",
    "    test_img,test_tar=img\n",
    "    test_imgo=test_img.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(test_imgo)\n",
    "    plt.title('Original Image')\n",
    "    plt.show()\n",
    "    model.eval()\n",
    "    pred=model(test_img.unsqueeze(0).to(D))\n",
    "# pred=torchvision.ops.nms(pred[0]['boxes'].detach(),pred[0]['scores'].detach(),0.02)\n",
    "    xmin,ymin,xmax,ymax=pred[0]['boxes'][0].detach().cpu().long().tolist()\n",
    "    label=pred[0]['labels'][0].item()\n",
    "    Txmin,Tymin,Txmax,Tymax=test_tar['boxes'][0].tolist()\n",
    "    image=cv2.rectangle(test_img.permute(1,2,0).numpy(),(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
    "    plt.imshow(image)\n",
    "    plt.title('predicted Image' )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "1H7_pk0KqN9z",
    "outputId": "54625baa-242b-451f-efe9-d5c02f901945",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx=290\n",
    "img=testset[idx]\n",
    "f(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvIKgxSfWa79"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('/content/test7.png')\n",
    "import numpy as np\n",
    "image = np.array(image)\n",
    "image = torch.Tensor(np.transpose(image,(2,0,1)))/255.0\n",
    "test_imgo=image.permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4296838,
     "sourceId": 7391382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
