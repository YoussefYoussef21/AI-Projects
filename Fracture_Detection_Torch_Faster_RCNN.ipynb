{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zmCLjp4pgjT",
    "outputId": "6320e680-d2fc-4a63-ada3-3080c79c3a74"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'bone-fracture-detection-computer-vision-project:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4296838%2F7391382%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240811%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240811T181410Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D55135b7e6ad141faefafe510657bceceb42eca6737fc52043406135ad5bf956ff34ace16f87ec6a2678dc2be09858dc6dfd53639a21d824362f62e026e968400ffd9522a0e3f08c3c780a2cd0ea5c7328b0736d902c611aef58b0d9c83b6e5c622e50cea4b58e8929361c00ab4b7b3d4aa6bf6f884db110010d7a585f24cb34cdc1183e9d49a7c49cf82065d12b360278ab2b5d859e69f5ed54703217d528d7b5d0ce78fe9d0454ec807eefbf997441c1e748ef4fc0faf4e4b307bbe1850b01109d24083e8f69a348a4d0b68db2a2ad1d70afed69249a6df1ce6791e22628474f8695f1860b47b38cbd09f287a6204bfd11806880c9d5f1605810ea727d582d6'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-21T16:07:55.973244Z",
     "iopub.status.busy": "2024-01-21T16:07:55.972953Z",
     "iopub.status.idle": "2024-01-21T16:08:02.703277Z",
     "shell.execute_reply": "2024-01-21T16:08:02.7023Z",
     "shell.execute_reply.started": "2024-01-21T16:07:55.973218Z"
    },
    "id": "PAKmfXFApgjV"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import albumentations as A\n",
    "import torchsummary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "BS=16\n",
    "LR=0.00005\n",
    "epochs=20\n",
    "IS=256\n",
    "D='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_classes = 7\n",
    "classes=['elbow positive', 'fingers positive', 'forearm fracture', 'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive']\n",
    "c2l={k:v for k,v in list(zip(classes,list(range(num_classes))))}\n",
    "l2c={v:k for k,v in c2l.items()}\n",
    "\n",
    "dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project'\n",
    "train_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/train'\n",
    "train_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/train/images'))\n",
    "train_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/train/labels'))\n",
    "\n",
    "val_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/valid'\n",
    "val_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/valid/images'))\n",
    "val_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/valid/labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:02.705414Z",
     "iopub.status.busy": "2024-01-21T16:08:02.704977Z",
     "iopub.status.idle": "2024-01-21T16:08:02.711671Z",
     "shell.execute_reply": "2024-01-21T16:08:02.710477Z",
     "shell.execute_reply.started": "2024-01-21T16:08:02.705387Z"
    },
    "id": "cU1-iPSvpgjW"
   },
   "outputs": [],
   "source": [
    "def unconvert(width, height, x, y, w, h):\n",
    "\n",
    "    xmax = int((x*width) + (w * width)/2.0)\n",
    "    xmin = int((x*width) - (w * width)/2.0)\n",
    "    ymax = int((y*height) + (h * height)/2.0)\n",
    "    ymin = int((y*height) - (h * height)/2.0)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:02.713175Z",
     "iopub.status.busy": "2024-01-21T16:08:02.712908Z",
     "iopub.status.idle": "2024-01-21T16:08:03.017Z",
     "shell.execute_reply": "2024-01-21T16:08:03.016038Z",
     "shell.execute_reply.started": "2024-01-21T16:08:02.713152Z"
    },
    "id": "NM8kGPJJpgjW",
    "outputId": "9f5ec617-a403-4b2e-bc72-2446e683a240"
   },
   "outputs": [],
   "source": [
    "idx=random.randint(0,3000)\n",
    "ip=os.path.join(train_dir_path,'images',train_img_paths[idx])\n",
    "tp=os.path.join(train_dir_path,'labels',train_target_paths[idx])\n",
    "\n",
    "image=cv2.imread(ip)\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "image=cv2.resize(image,(320,320))\n",
    "\n",
    "file=open(tp,'r')\n",
    "target=list(map(float,file.read().split()))[1:]\n",
    "\n",
    "a=0\n",
    "while a<len(target):\n",
    "    bbox=target[a:a+4]\n",
    "    if len(bbox)==4:\n",
    "        x,y,w,h=bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "        xmin,ymin,xmax,ymax=unconvert(320,320,x,y,w,h)\n",
    "        sp,ep=(xmin,ymin),(xmax,ymax)\n",
    "        image=cv2.rectangle(image,sp,ep,(255,0,0),2)\n",
    "    a+=4\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:47:13.829052Z",
     "iopub.status.busy": "2024-01-21T18:47:13.828214Z",
     "iopub.status.idle": "2024-01-21T18:47:13.833733Z",
     "shell.execute_reply": "2024-01-21T18:47:13.832759Z",
     "shell.execute_reply.started": "2024-01-21T18:47:13.829018Z"
    },
    "id": "QhE1X7g2pgjW"
   },
   "outputs": [],
   "source": [
    "augs=A.Compose([\n",
    "    A.Resize(IS,IS),\n",
    "],bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']), is_check_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:47:16.970946Z",
     "iopub.status.busy": "2024-01-21T18:47:16.970267Z",
     "iopub.status.idle": "2024-01-21T18:47:16.983584Z",
     "shell.execute_reply": "2024-01-21T18:47:16.982698Z",
     "shell.execute_reply.started": "2024-01-21T18:47:16.970911Z"
    },
    "id": "QECTpWOwpgjX"
   },
   "outputs": [],
   "source": [
    "class FractureData(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, img_paths, target_paths, augs=None):\n",
    "        self.dir_path=dir_path\n",
    "        self.img_paths=img_paths\n",
    "        self.target_paths=target_paths\n",
    "        self.augs=augs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        ip=os.path.join(self.dir_path,'images',self.img_paths[idx])\n",
    "        tp=os.path.join(self.dir_path,'labels',self.target_paths[idx])\n",
    "\n",
    "        image=cv2.imread(ip)\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        H,W,_=image.shape\n",
    "\n",
    "        file=open(tp,'r')\n",
    "        target=list(map(float,file.read().split()))\n",
    "\n",
    "        try:\n",
    "            label=[target.pop(0)]\n",
    "            bbox=[]\n",
    "            i=0\n",
    "            while i<len(target):\n",
    "                x,y,w,h=target[i:i+4]\n",
    "                bbox.append([*unconvert(W,H,x,y,w,h)])\n",
    "                i+=4\n",
    "            label=label*len(bbox)\n",
    "\n",
    "            if self.augs!=None:\n",
    "                data=self.augs(image=image,bboxes=bbox,class_labels=['None']*len(label))\n",
    "                image=data['image']\n",
    "                bbox=data['bboxes']\n",
    "        except:\n",
    "            if idx+1<len(self.img_paths):\n",
    "                return self.__getitem__(idx+1)\n",
    "            else:\n",
    "                return self.__getitem__(0)\n",
    "\n",
    "        image=torch.Tensor(np.transpose(image,(2,0,1)))/255.0\n",
    "        bbox=torch.Tensor(bbox).long()\n",
    "        label=torch.Tensor(label).long()\n",
    "\n",
    "        annot={'boxes':bbox,'labels':label}\n",
    "\n",
    "        return image, annot\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T18:47:17.220692Z",
     "iopub.status.busy": "2024-01-21T18:47:17.220089Z",
     "iopub.status.idle": "2024-01-21T18:47:17.226705Z",
     "shell.execute_reply": "2024-01-21T18:47:17.225847Z",
     "shell.execute_reply.started": "2024-01-21T18:47:17.220665Z"
    },
    "id": "zUQNdKEbpgjX",
    "outputId": "4ab180e5-5839-44b9-bc9d-d2d8ad02a1c9"
   },
   "outputs": [],
   "source": [
    "trainset=FractureData(train_dir_path, train_img_paths, train_target_paths, augs)\n",
    "valset=FractureData(val_dir_path, val_img_paths, val_target_paths, augs)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=BS,collate_fn=trainset.collate_fn)\n",
    "valloader=torch.utils.data.DataLoader(valset,batch_size=BS,collate_fn=valset.collate_fn)\n",
    "\n",
    "print(f'Training Data:- {len(trainset)} images divided into {len(trainloader)} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:03.059295Z",
     "iopub.status.busy": "2024-01-21T16:08:03.058997Z",
     "iopub.status.idle": "2024-01-21T16:08:04.392639Z",
     "shell.execute_reply": "2024-01-21T16:08:04.390812Z",
     "shell.execute_reply.started": "2024-01-21T16:08:03.05927Z"
    },
    "id": "NER7VT2WpgjX"
   },
   "outputs": [],
   "source": [
    "for image,target in trainloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:04.394432Z",
     "iopub.status.busy": "2024-01-21T16:08:04.394035Z",
     "iopub.status.idle": "2024-01-21T16:08:04.715388Z",
     "shell.execute_reply": "2024-01-21T16:08:04.714501Z",
     "shell.execute_reply.started": "2024-01-21T16:08:04.394397Z"
    },
    "id": "-IKRWhHtpgjY",
    "outputId": "00dcf0ad-fef2-49a6-83cc-462e16d026f6"
   },
   "outputs": [],
   "source": [
    "idx=random.randint(0,len(image))\n",
    "img, tar = image[idx].permute(1,2,0).numpy(), target[idx]\n",
    "\n",
    "for bbox in tar['boxes']:\n",
    "    xmin,ymin,xmax,ymax=bbox[0].item(), bbox[1].item(), bbox[2].item(), bbox[3].item()\n",
    "    sp,ep=(xmin,ymin),(xmax,ymax)\n",
    "    cv2.rectangle(img,sp,ep,(0,255,0),1)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(l2c[tar['labels'][0].item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGAqYOB4pgjY"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:04.716932Z",
     "iopub.status.busy": "2024-01-21T16:08:04.716638Z",
     "iopub.status.idle": "2024-01-21T16:08:06.352096Z",
     "shell.execute_reply": "2024-01-21T16:08:06.351318Z",
     "shell.execute_reply.started": "2024-01-21T16:08:04.716907Z"
    },
    "id": "NrFknhOepgjZ",
    "outputId": "03a5bd70-ef12-44a4-8e1d-710045b3e3af"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model=torchvision.models.detection.fasterrcnn_resnet50_fpn(preTrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.to(D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:06.354913Z",
     "iopub.status.busy": "2024-01-21T16:08:06.354623Z",
     "iopub.status.idle": "2024-01-21T16:08:06.364431Z",
     "shell.execute_reply": "2024-01-21T16:08:06.363493Z",
     "shell.execute_reply.started": "2024-01-21T16:08:06.354888Z"
    },
    "id": "b67eh80apgjZ"
   },
   "outputs": [],
   "source": [
    "def trainarc(model, dataloader, opt):\n",
    "    model.train()\n",
    "    train_loss=0.0\n",
    "\n",
    "    for images, targets in tqdm(dataloader):\n",
    "        image=[i.to(D) for i in images]\n",
    "        target=[{k:v.to(D) for k,v in ele.items()} for ele in targets]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        losses=model(image,target)\n",
    "        loss=sum(loss for loss in losses.values())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss+=loss\n",
    "    return train_loss/len(dataloader)\n",
    "\n",
    "def evalarc(model, dataloader):\n",
    "    model.train()\n",
    "    val_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader):\n",
    "            image=[i.to(D) for i in images]\n",
    "            target=[{k:v.to(D) for k,v in ele.items()} for ele in targets]\n",
    "\n",
    "            losses=model(image,target)\n",
    "            loss=sum( loss for loss in losses.values() )\n",
    "\n",
    "            val_loss+=loss\n",
    "    return val_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:06.366089Z",
     "iopub.status.busy": "2024-01-21T16:08:06.365709Z",
     "iopub.status.idle": "2024-01-21T18:17:45.078767Z",
     "shell.execute_reply": "2024-01-21T18:17:45.077858Z",
     "shell.execute_reply.started": "2024-01-21T16:08:06.366059Z"
    },
    "id": "7uEDk3r5pgjZ"
   },
   "outputs": [],
   "source": [
    "best_val_loss=np.Inf\n",
    "\n",
    "opt=torch.optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss=trainarc(model,trainloader,opt)\n",
    "    val_loss=evalarc(model,valloader)\n",
    "\n",
    "    print(f\"Epochs: {i+1}/{epochs}:- Trainloss: {train_loss}, Valloss: {val_loss}\")\n",
    "\n",
    "    if val_loss<best_val_loss:\n",
    "        torch.save(model.state_dict(),'/kaggle/working/model.pt')\n",
    "        print(\"Model Updated\")\n",
    "        best_val_loss=val_loss\n",
    "\n",
    "torch.save(model.state_dict(),'/kaggle/working/FullyTrainedModel.pt')\n",
    "print(\"Fully Trained Model Saved\")\n",
    "print(f\"Done. Best Val Loss: {best_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qy3vDOUEp3Yw",
    "outputId": "fa61d843-0087-468a-e44d-11f4b431b38e"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:47:27.627919Z",
     "iopub.status.busy": "2024-01-21T18:47:27.627103Z",
     "iopub.status.idle": "2024-01-21T18:47:27.634134Z",
     "shell.execute_reply": "2024-01-21T18:47:27.633224Z",
     "shell.execute_reply.started": "2024-01-21T18:47:27.627887Z"
    },
    "id": "ETMVdh0KpgjZ"
   },
   "outputs": [],
   "source": [
    "test_dir_path='/kaggle/input/bone-fracture-detection-computer-vision-project/test'\n",
    "test_img_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/test/images'))\n",
    "test_target_paths = sorted(os.listdir('/kaggle/input/bone-fracture-detection-computer-vision-project/test/labels'))\n",
    "\n",
    "testset=FractureData(test_dir_path, test_img_paths, test_target_paths, augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T19:14:25.852306Z",
     "iopub.status.busy": "2024-01-21T19:14:25.851939Z",
     "iopub.status.idle": "2024-01-21T19:14:26.201981Z",
     "shell.execute_reply": "2024-01-21T19:14:26.201066Z",
     "shell.execute_reply.started": "2024-01-21T19:14:25.852276Z"
    },
    "id": "CafCRpscpgja"
   },
   "outputs": [],
   "source": [
    "\n",
    "def f(img):\n",
    "    test_img,test_tar=img\n",
    "    test_imgo=test_img.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(test_imgo)\n",
    "    plt.title('Original Image')\n",
    "    plt.show()\n",
    "    model.eval()\n",
    "    pred=model(test_img.unsqueeze(0).to(D))\n",
    "    pred=torchvision.ops.nms(pred[0]['boxes'].detach(),pred[0]['scores'].detach(),0.02)\n",
    "    xmin,ymin,xmax,ymax=pred[0]['boxes'][0].detach().cpu().long().tolist()\n",
    "    label=pred[0]['labels'][0].item()\n",
    "    Txmin,Tymin,Txmax,Tymax=test_tar['boxes'][0].tolist()\n",
    "    image=cv2.rectangle(test_img.permute(1,2,0).numpy(),(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
    "    image=cv2.rectangle(image,(Txmin,Tymin),(Txmax,Tymax),(0,255,0),2)\n",
    "    plt.imshow(image)\n",
    "    plt.title('predicted Image' )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "1H7_pk0KqN9z",
    "outputId": "78d4871b-78e4-4d3f-a029-9efe8c662b4e"
   },
   "outputs": [],
   "source": [
    "idx=random.randint(0,len(testset)-1)\n",
    "img=testset[idx]\n",
    "f(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Fracture Detection - Torch Faster RCNN",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4296838,
     "sourceId": 7391382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
